import streamlit as st
from sentence_transformers import SentenceTransformer
import faiss
import os
import json
import pandas as pd
import numpy as np
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA

# 0. JSON ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def load_tifu_json(path: str) -> pd.DataFrame:
    records = []
    for fname in os.listdir(path):
        if fname.endswith('.json'):
            with open(os.path.join(path, fname), 'r', encoding='utf-8') as f:
                for line in f:
                    data = json.loads(line)
                    records.append({
                        'text': f"Title: {data.get('title','')}\n{data.get('selftext','')}",
                        'source': 'TIFU',
                        'ups': data.get('ups', 0)
                    })
    return pd.DataFrame(records)

@st.cache_data
def load_aita_json(path: str) -> pd.DataFrame:
    records = []
    for fname in os.listdir(path):
        if fname.endswith('.json'):
            with open(os.path.join(path, fname), 'r', encoding='utf-8') as f:
                for line in f:
                    data = json.loads(line)
                    verdict = data.get('judge', '')
                    records.append({
                        'text': f"Post: {data.get('text','')}\nVerdict: {verdict}",
                        'source': 'AITA',
                        'verdict': verdict
                    })
    return pd.DataFrame(records)

# 1. ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•
@st.cache_resource
def build_vectorstore(tifu_path, aita_path, embedding_model="sentence-transformers/all-MiniLM-L6-v2", index_dir="./vectorstore"):
    df = pd.concat([load_tifu_json(tifu_path), load_aita_json(aita_path)], ignore_index=True)
    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)
    texts = df['text'].tolist()
    vectors = embeddings.embed_documents(texts)
    dim = len(vectors[0])
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(vectors, dtype='float32'))
    os.makedirs(index_dir, exist_ok=True)
    faiss.write_index(index, os.path.join(index_dir, 'index.faiss'))
    df.to_pickle(os.path.join(index_dir, 'metadata.pkl'))
    return index_dir

# 2. FAISS ë¡œë“œ
@st.cache_resource
def load_vectorstore(index_dir, embedding_model="sentence-transformers/all-MiniLM-L6-v2"):
    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)
    # allow_dangerous_deserialization=True ë¡œ pickle ë¡œë“œ í—ˆìš©
    return FAISS.load_local(index_dir, embeddings, allow_dangerous_deserialization=True)

# 3. QA ì²´ì¸
@st.cache_resource
def init_qa_chain(vectorstore):
    retriever = vectorstore.as_retriever(search_kwargs={"k":5})
    openai_key = st.secrets["openai"]["api_key"]
    llm = OpenAI(
        model_name="gpt-4o-mini",
        openai_api_key=openai_key,
        temperature=0.7
    )
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=False
    )

# 4. Streamlit UI

def main():
    st.set_page_config(
        page_title="ì‹¤ìˆ˜ ë¦¬í”„ë ˆì´ë¨¸ ì±—ë´‡",
        layout="wide",
        initial_sidebar_state="collapsed"
    )

    # ì•± í—¤ë”
    col1, col2 = st.columns([1,4])
    with col1:
        st.image("https://i.imgur.com/your_logo.png", width=80)
    with col2:
        st.title("ğŸ˜… ì‹¤ìˆ˜ ë¦¬í”„ë ˆì´ë¨¸ ì±—ë´‡")
        st.markdown("_ì‘ì€ ì‹¤ìˆ˜ë„ ìœ„ì¸ë“¤ì˜ ì‹¤íŒ¨ì™€ ë¹„êµí•˜ë©° ë§ˆìŒì˜ ì§ì„ ëœì–´ë³´ì„¸ìš”_ ")

    # íƒ­ êµ¬ì„±
    tabs = st.tabs(["ì±—", "ì„¤ì •", "íˆìŠ¤í† ë¦¬"])

    # ì±— íƒ­
    with tabs[0]:
        st.subheader("ì—¬ê¸°ì— ì‹¤ìˆ˜ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”!")
        user_input = st.text_area("ë‹¹ì‹ ì˜ ì‹¤ìˆ˜:", height=100)
        if st.button("ìœ„ë¡œë°›ê¸°", key="run"):  
            if user_input.strip():
                with st.spinner("ìœ„ë¡œë¥¼ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤..."):
                    response = qa_chain.run(user_input)
                st.markdown("---")
                st.markdown("**ğŸ¤– ë¦¬í”„ë ˆì´ë° ë‹µë³€:**")
                st.write(response)
            else:
                st.warning("ë¨¼ì € ì‹¤ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ì„¤ì • íƒ­
    with tabs[1]:
        st.subheader("ë°ì´í„° & ì¸ë±ìŠ¤ ì„¤ì •")
        tifu_path = st.text_input("TIFU JSON í´ë” ê²½ë¡œ", "./data/tifu_json")
        aita_path = st.text_input("AITA JSON í´ë” ê²½ë¡œ", "./data/aita_json")
        index_dir = st.text_input("FAISS ì¸ë±ìŠ¤ í´ë”", "./vectorstore")
        if st.button("ìƒ‰ì¸ ì¬ìƒì„±", key="reindex"):
            build_vectorstore(tifu_path, aita_path, index_dir=index_dir)
            st.success("ìƒ‰ì¸ì´ ì¬ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.caption("ë°ì´í„° ë³€ê²½ ì‹œ ì¬ìƒì„±í•˜ì„¸ìš”.")

    # íˆìŠ¤í† ë¦¬ íƒ­
    with tabs[2]:
        st.subheader("ëŒ€í™” íˆìŠ¤í† ë¦¬")
        if 'history' not in st.session_state:
            st.session_state.history = []
        for entry in st.session_state.history:
            st.markdown(f"- **ì§ˆë¬¸:** {entry['q']}")
            st.markdown(f"  **ë‹µë³€:** {entry['a']}\n")

if __name__ == '__main__':
    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    default_tifu = "./data/tifu_json"
    default_aita = "./data/aita_json"
    default_index = "./vectorstore"

    # ìƒ‰ì¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    index_file = os.path.join(default_index, 'index.faiss')
    if not os.path.exists(index_file):
        st.warning("vectorstoreê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„° í´ë”ë¥¼ ë¶ˆëŸ¬ì™€ ìƒ‰ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        build_vectorstore(default_tifu, default_aita, index_dir=default_index)

    # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ë° QA ì²´ì¸ ì´ˆê¸°í™”
    vectorstore = load_vectorstore(default_index)
    qa_chain = init_qa_chain(vectorstore)

    main()
