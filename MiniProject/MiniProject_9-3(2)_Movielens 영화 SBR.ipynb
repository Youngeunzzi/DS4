{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2841b69",
   "metadata": {},
   "source": [
    "# <노드 학습>\n",
    "- 미니 프로젝트 주제: Movielens 1M Dataset을 기반으로, Session based Recommendation 시스템을 제작해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6122568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import tensorflow\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6deb7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5682ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:40:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-20 13:44:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating                Time\n",
       "31            1    3186       4 2000-12-31 22:00:19\n",
       "22            1    1270       5 2000-12-31 22:00:55\n",
       "27            1    1721       4 2000-12-31 22:00:55\n",
       "37            1    1022       5 2000-12-31 22:00:55\n",
       "24            1    2340       3 2000-12-31 22:01:43\n",
       "...         ...     ...     ...                 ...\n",
       "1000019    6040    2917       4 2001-08-10 14:40:29\n",
       "999988     6040    1921       4 2001-08-10 14:41:04\n",
       "1000172    6040    1784       3 2001-08-10 14:41:04\n",
       "1000167    6040     161       3 2001-08-10 14:41:26\n",
       "1000042    6040    1221       4 2001-08-20 13:44:15\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(os.getenv('HOME')+'/aiffel/yoochoose/data/') \n",
    "train_path = data_path / 'ratings.dat'\n",
    "\n",
    "def load_data(data_path: Path, nrows=None):\n",
    "    data = pd.read_csv(data_path, sep='::', header=None, usecols=[0, 1, 2, 3], dtype={0: np.int32, 1: np.int32, 2: np.int32}, nrows=nrows)\n",
    "    data.columns = ['UserId', 'ItemId', 'Rating', 'Time']\n",
    "    # time 형식을 기존과 맞게 고쳐보기\n",
    "    data['Time'] = pd.to_datetime(data['Time'], unit='s')\n",
    "    return data\n",
    "\n",
    "data = load_data(train_path, None)\n",
    "data.sort_values(['UserId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬해줍니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9a4d5",
   "metadata": {},
   "source": [
    "- 위에서 이전 학습(9-3(1))과 가장 크게 다른 부분 -> SessionID 대신 UserID 항목이 들어갔다는 점!\n",
    "- 이 데이터셋은 명확한 1회 세션의 SessionID를 포함하지 않는다. 그래서 이번에는 UserID가 SessionID의 역할을 해야한다.\n",
    "- 또한 Rating 정보가 포함되어 있음 -> Rating 정보가 포함됨으로써, 직전에 봤던 영화가 마음에 들었는지가 비슷한 영화를 더 고르게 하는 것과 상관이 있을 수도 있다! \n",
    "    - Rating이 낮은 데이터 또한 어떻게 처리할지도 고민해봐야 하는 문제이다.\n",
    "- Time 항목에는 UTC time이 포함되어, 1970년 1월 1일부터 경과된 초 단위의 시간이 기재되어 있다.\n",
    "- 이 내용들을 바탕으로, 한번 프로젝트를 해보자..!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b186f",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 전처리\n",
    "- cleanse_recursive(data, shortest, least_click) -> 짧은 세션과 인기가 없는 아이템을 반복적으로 제거한다.\n",
    "    - while True 루프를 통해서, 데이터의 변화가 없을 때까지 전처리를 반복한다.\n",
    "- cleanse_short_session(data: pd.DataFrame, shortest) -> UserId를 세션 단위로 보고, 각 사용자 세션의 길이를 계산하고 shortest 이상인 세션만 필터링한다.\n",
    "- cleanse_unpopular_item(data: pd.DataFrame, least_click) -> 각 아이템이 얼마나 자주 클릭(평점)됐는지를 기준으로, least_click 미만인 아이템은 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88daa796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이부분을 이 데이터에 맞게 고치기\n",
    "\n",
    "# short_session을 제거한 다음 unpopular item을 제거하면 다시 길이가 1인 session이 생길 수 있습니다.\n",
    "# 이를 위해 반복문을 통해 지속적으로 제거 합니다.\n",
    "def cleanse_recursive(data: pd.DataFrame, shortest, least_click) -> pd.DataFrame:\n",
    "    while True:\n",
    "        before_len = len(data)\n",
    "        data = cleanse_short_session(data, shortest)\n",
    "        data = cleanse_unpopular_item(data, least_click)\n",
    "        after_len = len(data)\n",
    "        if before_len == after_len:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_short_session(data: pd.DataFrame, shortest):\n",
    "    session_len = data.groupby('UserId').size()\n",
    "    session_use = session_len[session_len >= shortest].index\n",
    "    data = data[data['UserId'].isin(session_use)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_unpopular_item(data: pd.DataFrame, least_click):\n",
    "    item_popular = data.groupby('ItemId').size()\n",
    "    item_use = item_popular[item_popular >= least_click].index\n",
    "    data = data[data['ItemId'].isin(item_use)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0b97cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = cleanse_recursive(data, shortest=2, least_click=5)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66034beb",
   "metadata": {},
   "source": [
    "- 그 다음, 세션 수(UserId 기준 고유값 수)를 출력한다.\n",
    "- 여기서 nunique()를 활용하여, 전체 세션의 개수를 확인한다. (UserId를 SessionId처럼 사용함)\n",
    "- 전체 중에서 세션 길이가 1인 세션의 비율을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5622b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 세션 수: 6040\n",
      "세션별 길이(상위 10개):\n",
      "UserId\n",
      "4169    2314\n",
      "1680    1850\n",
      "4277    1743\n",
      "1941    1595\n",
      "1181    1521\n",
      "889     1518\n",
      "3618    1344\n",
      "2063    1323\n",
      "1150    1302\n",
      "1015    1286\n",
      "dtype: int64\n",
      "길이 1 세션 비율: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 1) 세션 길이 분포 확인\n",
    "print(\"검증 세션 수:\", data['UserId'].nunique())\n",
    "print(\"세션별 길이(상위 10개):\")\n",
    "print(data.groupby('UserId').size().sort_values(ascending=False).head(10))\n",
    "\n",
    "# 2) 길이 1인 세션 개수\n",
    "print(\"길이 1 세션 비율:\",\n",
    "      (data.groupby('UserId').size() == 1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000004ab",
   "metadata": {},
   "source": [
    "- 그 다음, split_by_date(data: pd.DataFrame, n_days: int) -> n_day를 기준으로 최근 데이터를 test 데이터 셋, 나머지를 train 데이터 셋으로 나눈다.\n",
    "- Step1에서 전처리된 전체 데이터를 기준으로, 마지막 14일치 데이터를 test 데이터 셋으로 분리하고, 그 이전 데이터에서 다시 마지막 14일치를 validation 데이터 셋으로 분리하고, 나머지 데이터를 최종 train 데이터 셋 용도로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada7ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(data: pd.DataFrame, n_days: int):\n",
    "    final_time = data['Time'].max()\n",
    "    cutoff_time = final_time - dt.timedelta(days=n_days)\n",
    "\n",
    "    # Train: cutoff 이전의 데이터\n",
    "    train = data[data['Time'] < cutoff_time]\n",
    "\n",
    "    # Test: cutoff 이후의 데이터, 단 아이템은 train에 있던 것만\n",
    "    test = data[(data['Time'] >= cutoff_time) & (data['ItemId'].isin(train['ItemId']))]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b95dbe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, test = split_by_date(data, n_days=14)  # 마지막 이틀만 테스트용으로 분리\n",
    "tr, val = split_by_date(tr, n_days=14)  # 마지막 이틀만 테스트용으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d7b79",
   "metadata": {},
   "source": [
    "- 데이터 셋의 기초 통계 정보를 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000e369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data에 대한 정보를 살펴봅니다.\n",
    "def stats_info(data: pd.DataFrame, status: str):\n",
    "    print(f'* {status} Set Stats Info\\n'\n",
    "          f'\\t Events: {len(data)}\\n'\n",
    "          f'\\t Sessions: {data[\"UserId\"].nunique()}\\n'\n",
    "          f'\\t Items: {data[\"ItemId\"].nunique()}\\n'\n",
    "          f'\\t First Time : {data[\"Time\"].min()}\\n'\n",
    "          f'\\t Last Time : {data[\"Time\"].max()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6e871",
   "metadata": {},
   "source": [
    "# 클렌징을 추가로 진행해줘야함\n",
    "- 이제, train/validation/test 세트에 대해서도 전처리를 적용하고, 이것들에 대해서도 기초 통계 정보를 확인해본다.\n",
    "- 아래 코드는, 세션의 길이가 2보다 작은것을 제거하고, 적게 클릭된 아이템(train: 5회 미만 // val/test: 1회 미만)을 제거한다.\n",
    "- 아래 코드에서 val, test는 너무 많은 데이터를 제거하지 않도록 하기 위해서 least_click=1로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d87b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = cleanse_recursive(tr, shortest=2, least_click=5)\n",
    "val = cleanse_recursive(val, shortest=2, least_click=1)\n",
    "test = cleanse_recursive(test, shortest=2, least_click=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5d92d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train Set Stats Info\n",
      "\t Events: 998112\n",
      "\t Sessions: 6040\n",
      "\t Items: 3416\n",
      "\t First Time : 2000-04-25 23:05:32\n",
      "\t Last Time : 2003-01-31 12:16:30\n",
      "\n",
      "* valid Set Stats Info\n",
      "\t Events: 883\n",
      "\t Sessions: 39\n",
      "\t Items: 692\n",
      "\t First Time : 2003-01-31 17:23:06\n",
      "\t Last Time : 2003-02-14 02:02:32\n",
      "\n",
      "* test Set Stats Info\n",
      "\t Events: 575\n",
      "\t Sessions: 44\n",
      "\t Items: 489\n",
      "\t First Time : 2003-02-15 00:15:09\n",
      "\t Last Time : 2003-02-28 17:49:50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_info(tr, 'train')\n",
    "stats_info(val, 'valid')\n",
    "stats_info(test, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa31ba",
   "metadata": {},
   "source": [
    "## Step 2. 미니 배치의 구성\n",
    "- 먼저, 훈련 데이터(tr)에 등장하는 고유한 아이템Id를 기준으로, 각 아이템에 고유한 정수 인덱스를 부여한다.\n",
    "- 그리고, 데이터프레임(tr, val, test)에 대해서 아이템Id를 정수 인덱스(item_idx)로 변환한다. 이때, id2idx에 없는 아이템은 -1로 처리하여 모델에 노출되지 않도록 한다. (콜드 스타트 문제 해결하기 위함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217c022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set에 없는 아이템이 val, test기간에 생길 수 있으므로 train data를 기준으로 인덱싱합니다.\n",
    "id2idx = {item_id : index for index, item_id in enumerate(tr['ItemId'].unique())}\n",
    "\n",
    "def indexing(df, id2idx):\n",
    "    df['item_idx'] = df['ItemId'].map(lambda x: id2idx.get(x, -1))  # id2idx에 없는 아이템은 모르는 값(-1) 처리 해줍니다.\n",
    "    return df\n",
    "\n",
    "tr = indexing(tr, id2idx)\n",
    "val = indexing(val, id2idx)\n",
    "test = indexing(test, id2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd965738",
   "metadata": {},
   "source": [
    "- 그 다음, 검증 데이터 셋(val)에 대한 세션 분석을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09fa878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 세션 수: 39\n",
      "세션별 길이(상위 10개):\n",
      "UserId\n",
      "398     220\n",
      "3012    165\n",
      "4958    133\n",
      "419      79\n",
      "5654     72\n",
      "5172     61\n",
      "195      13\n",
      "4312     12\n",
      "2648     12\n",
      "3732     11\n",
      "dtype: int64\n",
      "길이 1 세션 비율: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 1) 세션 길이 분포 확인\n",
    "print(\"검증 세션 수:\", val['UserId'].nunique())\n",
    "print(\"세션별 길이(상위 10개):\")\n",
    "print(val.groupby('UserId').size().sort_values(ascending=False).head(10))\n",
    "\n",
    "# 2) 길이 1인 세션 개수\n",
    "print(\"길이 1 세션 비율:\",\n",
    "      (val.groupby('UserId').size() == 1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5cd499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:40:29</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:26</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-20 13:44:15</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998112 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating                Time  item_idx\n",
       "31            1    3186       4 2000-12-31 22:00:19         0\n",
       "22            1    1270       5 2000-12-31 22:00:55         1\n",
       "27            1    1721       4 2000-12-31 22:00:55         2\n",
       "37            1    1022       5 2000-12-31 22:00:55         3\n",
       "24            1    2340       3 2000-12-31 22:01:43         4\n",
       "...         ...     ...     ...                 ...       ...\n",
       "1000019    6040    2917       4 2001-08-10 14:40:29      1248\n",
       "999988     6040    1921       4 2001-08-10 14:41:04       370\n",
       "1000172    6040    1784       3 2001-08-10 14:41:04        89\n",
       "1000167    6040     161       3 2001-08-10 14:41:26       464\n",
       "1000042    6040    1221       4 2001-08-20 13:44:15       430\n",
       "\n",
       "[998112 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4340a461",
   "metadata": {},
   "source": [
    "- SessionDataset -> 세션 기반 추천 모델 학습을 위한 세션 단위 데이터셋 구성 클래스를 생성한다. 이는 세션별 클릭 순서를 빠르게 추출하기 위해 세션 인덱스, 오프셋 정보를 저장한다.\n",
    "- 즉, 미니배치 구성을 위한 세션 인덱싱 구조를 준비하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de59249",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataset:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        self.click_offsets = self.get_click_offsets()\n",
    "        self.session_idx = np.arange(self.df['UserId'].nunique())  # indexing to SessionId\n",
    "\n",
    "    def get_click_offsets(self):\n",
    "        \"\"\"\n",
    "        Return the indexes of the first click of each session IDs,\n",
    "        \"\"\"\n",
    "        offsets = np.zeros(self.df['UserId'].nunique() + 1, dtype=np.int32)\n",
    "        offsets[1:] = self.df.groupby('UserId').size().cumsum()\n",
    "        return offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dfd856",
   "metadata": {},
   "source": [
    "- 세션 구조가 잘 유지됐는지 확인하기 위해, 전처리된 데이터프레임의 상위 10개 행을 출력해본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bec6ab24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1836</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:02:52</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:04:35</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:11:59</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1207</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:11:59</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserId  ItemId  Rating                Time  item_idx\n",
       "31       1    3186       4 2000-12-31 22:00:19         0\n",
       "22       1    1270       5 2000-12-31 22:00:55         1\n",
       "27       1    1721       4 2000-12-31 22:00:55         2\n",
       "37       1    1022       5 2000-12-31 22:00:55         3\n",
       "24       1    2340       3 2000-12-31 22:01:43         4\n",
       "36       1    1836       5 2000-12-31 22:02:52         5\n",
       "3        1    3408       4 2000-12-31 22:04:35         6\n",
       "7        1    2804       5 2000-12-31 22:11:59         7\n",
       "47       1    1207       4 2000-12-31 22:11:59         8\n",
       "0        1    1193       5 2000-12-31 22:12:40         9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset = SessionDataset(tr)\n",
    "tr_dataset.df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab390a7",
   "metadata": {},
   "source": [
    "- 아래 코드는, 각 UserId(세션)이 시작하는 인덱스 위치를 저장한 배열을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1824e66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,     53,    182, ..., 997648, 997771, 998112], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset.click_offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eaab64",
   "metadata": {},
   "source": [
    "- 전체 세션의 인덱스를 0부터 차례대로 나열한 세션 번호 배열을 출력해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce7e69d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 6037, 6038, 6039])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset.session_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf7d23",
   "metadata": {},
   "source": [
    "- 선색한 세션(여기서는 0,1,2,3)의 시작 위치와 종료 위치 바로 다음의 인덱스를 가져온다. 이를 통해 각 세션의 데이터를 start[i]:end[i] 범위로 슬라이싱할 수 있다.\n",
    "    - start: 각 세션의 시작 인덱스 배열\n",
    "    - end: 각 세션의 종료 인덱스 +1 위치 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "198943d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 53, 182, 233, 254], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = tr_dataset.click_offsets[tr_dataset.session_idx[[[0,1,2,3]]]]       # data 상에서 session이 시작된 위치를 가져옵니다.\n",
    "end = tr_dataset.click_offsets[tr_dataset.session_idx[[0,1,2,3]] + 1]  # session이 끝난 위치 바로 다음 위치를 가져옵니다.\n",
    "\n",
    "start\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089f0ba",
   "metadata": {},
   "source": [
    "- 아래 코드는, 선택한 세션 중 가장 짧은 세션의 길이에서 1을 뺀 값을 구함으로써, 모든 세션에서 입력과 라벨로 나눌 수 있는 최소 시퀀스 길이를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5dd74cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end - start).min() -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf08d26",
   "metadata": {},
   "source": [
    "- 각 세션 시작 위치(start)에 20을 더한 인덱스에서 item_idx 값을 추출한다.\n",
    "- 즉, 각 세션의 21번째 아이템 인덱스들을 배열로 가져오는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8194e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20,  71, 185,  88])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = tr_dataset.df['item_idx'].values[start + 20]\n",
    "inp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b81a26",
   "metadata": {},
   "source": [
    "- 그 다음, 각 세션에서 21번째 입력 다음에 등장하는 아이템 인덱스들 즉, 예측 대상(target)을 추출한다.\n",
    "- 이 코드는 start+20 위치의 inp를 보고, target인 start+21을 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6addf935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21,  72, 186,  56])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = tr_dataset.df['item_idx'].values[start + 20 + 1]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f08e43",
   "metadata": {},
   "source": [
    "- 아래 코드는 SessionDataLoader 클래스를 구현하여, 세션 데이터를 병렬로 처리할 수 있도록 입력과 타겟을 순차적으로 생성하며, 남은 세션의 수가 batch_size보다 적을 경우 자동으로 조정하여 처리 누락을 방지하는 코드이다.\n",
    "- self.batch_size = min(batch_size, len(dataset.session_idx)) -> 남은 세션 수에 맞춰 배치 크기 자동 조정한다.\n",
    "- __iter__ -> 세션별 item_idx를 이용해 입력/타깃 시퀀스를 생성한다.\n",
    "- initialize / update_status -> 세션이 끝날 때마다 다음 세션으로 교체한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbeacf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataLoader:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, dataset: SessionDataset, batch_size=50):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "## 이부분에 batch_size 를 마지막에 남은 부분으 처리할수있게 코드 작성\n",
    "#         self.batch_size = batch_size\n",
    "        self.batch_size = min(batch_size, len(dataset.session_idx))  # 이 줄 추가\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n",
    "        Yields:\n",
    "            input (B,):  Item indices that will be encoded as one-hot vectors later.\n",
    "            target (B,): a Variable that stores the target item indices\n",
    "            masks: Numpy array indicating the positions of the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        start, end, mask, last_session, finished = self.initialize()  # initialize 메소드에서 확인해주세요.\n",
    "        \"\"\"\n",
    "        start : Index Where Session Start\n",
    "        end : Index Where Session End\n",
    "        mask : indicator for the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        while not finished:\n",
    "            min_len = (end - start).min() - 1  # Shortest Length Among Sessions\n",
    "            for i in range(min_len):\n",
    "                # Build inputs & targets\n",
    "                inp = self.dataset.df['item_idx'].values[start + i]\n",
    "                target = self.dataset.df['item_idx'].values[start + i + 1]\n",
    "                yield inp, target, mask\n",
    "\n",
    "            start, end, mask, last_session, finished = self.update_status(start, end, min_len, last_session, finished)\n",
    "\n",
    "    def initialize(self):\n",
    "        first_iters = np.arange(self.batch_size)    # 첫 배치에 사용할 세션 Index를 가져옵니다.\n",
    "        last_session = self.batch_size - 1    # 마지막으로 다루고 있는 세션 Index를 저장해둡니다.\n",
    "        start = self.dataset.click_offsets[self.dataset.session_idx[first_iters]]       # data 상에서 session이 시작된 위치를 가져옵니다.\n",
    "        end = self.dataset.click_offsets[self.dataset.session_idx[first_iters] + 1]  # session이 끝난 위치 바로 다음 위치를 가져옵니다.\n",
    "        mask = np.array([])   # session의 모든 아이템을 다 돌은 경우 mask에 추가해줄 것입니다.\n",
    "        finished = False         # data를 전부 돌았는지 기록하기 위한 변수입니다.\n",
    "        return start, end, mask, last_session, finished\n",
    "\n",
    "    def update_status(self, start: np.ndarray, end: np.ndarray, min_len: int, last_session: int, finished: bool):\n",
    "        # 다음 배치 데이터를 생성하기 위해 상태를 update합니다.\n",
    "\n",
    "        start += min_len   # __iter__에서 min_len 만큼 for문을 돌았으므로 start를 min_len 만큼 더해줍니다.\n",
    "        mask = np.arange(self.batch_size)[(end - start) == 1]\n",
    "        # end는 다음 세션이 시작되는 위치인데 start와 한 칸 차이난다는 것은 session이 끝났다는 뜻입니다. mask에 기록해줍니다.\n",
    "\n",
    "        for i, idx in enumerate(mask, start=1):  # mask에 추가된 세션 개수만큼 새로운 세션을 돌것입니다.\n",
    "            new_session = last_session + i\n",
    "            if new_session > self.dataset.session_idx[-1]:  # 만약 새로운 세션이 마지막 세션 index보다 크다면 모든 학습데이터를 돈 것입니다.\n",
    "                finished = True\n",
    "                break\n",
    "            # update the next starting/ending point\n",
    "            start[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session]]     # 종료된 세션 대신 새로운 세션의 시작점을 기록합니다.\n",
    "            end[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session] + 1]\n",
    "\n",
    "        last_session += len(mask)  # 마지막 세션의 위치를 기록해둡니다.\n",
    "        return start, end, mask, last_session, finished"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6dcbba",
   "metadata": {},
   "source": [
    "- 미니배치 구성이 잘 될지 확인하기 위해, 세션 데이터 상위 15개를 출력하여 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "974070c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1836</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:02:52</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:04:35</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:11:59</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1207</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:11:59</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:22:48</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:23:18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>2692</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:26:10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserId  ItemId  Rating                Time  item_idx\n",
       "31       1    3186       4 2000-12-31 22:00:19         0\n",
       "22       1    1270       5 2000-12-31 22:00:55         1\n",
       "27       1    1721       4 2000-12-31 22:00:55         2\n",
       "37       1    1022       5 2000-12-31 22:00:55         3\n",
       "24       1    2340       3 2000-12-31 22:01:43         4\n",
       "36       1    1836       5 2000-12-31 22:02:52         5\n",
       "3        1    3408       4 2000-12-31 22:04:35         6\n",
       "7        1    2804       5 2000-12-31 22:11:59         7\n",
       "47       1    1207       4 2000-12-31 22:11:59         8\n",
       "0        1    1193       5 2000-12-31 22:12:40         9\n",
       "21       1     720       3 2000-12-31 22:12:40        10\n",
       "44       1     260       4 2000-12-31 22:12:40        11\n",
       "9        1     919       4 2000-12-31 22:22:48        12\n",
       "51       1     608       4 2000-12-31 22:23:18        13\n",
       "43       1    2692       4 2000-12-31 22:26:10        14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data_loader = SessionDataLoader(tr_dataset, batch_size=4)\n",
    "tr_dataset.df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951071e8",
   "metadata": {},
   "source": [
    "- SessionDataLoader에서 첫번째 미니 배치를 꺼내서, 모델 입력(inputs), 정답 라벨(labels), 종료된 세션 마스크(mask)를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "586b8a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Item Idx are : [ 0 53 65 54]\n",
      "Label Item Idx are :       [ 1 54 62 24]\n",
      "Previous Masked Input Idx are []\n"
     ]
    }
   ],
   "source": [
    "iter_ex = iter(tr_data_loader)\n",
    "\n",
    "inputs, labels, mask =  next(iter_ex)\n",
    "print(f'Model Input Item Idx are : {inputs}')\n",
    "print(f'Label Item Idx are : {\"\":5} {labels}')\n",
    "print(f'Previous Masked Input Idx are {mask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a9521",
   "metadata": {},
   "source": [
    "- 이제, 추천 결과 평가 지표인 MRR@k와 Recall@k를 계산한다.\n",
    "    - mrr_k(pred, truth, k) -> 정답 아이템(truth)이 상위 k개 예측 중 몇 번째에 있는지를 보고, **역순위 평균(MRR)**을 반환한다.\n",
    "    - recall_k(pred, truth, k) -> 정답 아이템이 상위 k개 예측 안에 있으면 1, 없으면 0을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab670380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_k(pred, truth: int, k: int):\n",
    "    indexing = np.where(pred[:k] == truth)[0]\n",
    "    if len(indexing) > 0:\n",
    "        return 1 / (indexing[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def recall_k(pred, truth: int, k: int) -> int:\n",
    "    answer = truth in pred[:k]\n",
    "    return int(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7609a2",
   "metadata": {},
   "source": [
    "## Step 3. 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87e1381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GRU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c5e77",
   "metadata": {},
   "source": [
    "- 아래 코드의 create_model 함수 간단한 설명\n",
    "    - 입력 -> (배치 크기, 타임스텝=1, 아이템 수) 형태의 원-핫 인코딩된 시퀀스 형태이다.\n",
    "    - GRU 층에서 이 시퀀스를 처리하고, stateful=True로 설정하여, 세션간의 순서를 유지하면서 학습이 가능하게끔 한다.\n",
    "    - 또한, 과적합 방지를 위해 드롭아웃을 넣었다.\n",
    "    - 출력층 -> 모든 아이템에 대한 softmax 확률 분포를 출력한다.\n",
    "    - 모델을 정의하고, CrossEntropy + Adam optimizer로 compile한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66a233ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args):\n",
    "    inputs = Input(batch_shape=(args.batch_size, 1, args.num_items))\n",
    "    gru, _ = GRU(args.hsz, stateful=True, return_state=True, name='GRU')(inputs)\n",
    "    dropout = Dropout(args.drop_rate)(gru)\n",
    "    predictions = Dense(args.num_items, activation='softmax')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=[predictions])\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(args.lr), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fcefc9",
   "metadata": {},
   "source": [
    "- 아래 코드는, 모델 학습 및 평가에 필요한 하이퍼파라미터와 데이터 셋을 한번에 담는 클래스를 정의한것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db913549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, tr, val, test, batch_size, hsz, drop_rate, lr, epochs, k):\n",
    "        self.tr = tr\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.num_items = tr['ItemId'].nunique()\n",
    "        self.num_sessions = tr['UserId'].nunique()\n",
    "        self.batch_size = batch_size\n",
    "        self.hsz = hsz\n",
    "        self.drop_rate = drop_rate\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.k = k\n",
    "\n",
    "## 배치사이즈를 너무 크게두면 밑에 평가 부분에서 nan이 나옵니다    \n",
    "args = Args(tr, val, test, batch_size=256, hsz=50, drop_rate=0.1, lr=0.001, epochs=3, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06f5f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(256, 1, 3416)]          0         \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    [(256, 50), (256, 50)]    520200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (256, 50)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (256, 3416)               174216    \n",
      "=================================================================\n",
      "Total params: 694,416\n",
      "Trainable params: 694,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12ff92",
   "metadata": {},
   "source": [
    "- 여기까지 했으면, 일단 모델이 학습할 준비는 다 마친 상태이다..!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849b6e1",
   "metadata": {},
   "source": [
    "## Step 4. 모델 학습\n",
    "- 아래 코드는 GRU 모델을 세션 기반 미니배치로 학습하고, 각 epoch마다 검증 데이터(val)로 Recall@k, MRR@k를 계산하여 성능을 평가하는 코드이다. 여기서 GRU의 stateful=True 특성상, 세션 종료마다 hidden state를 초기화한다.\n",
    "- train_model(model, args) -> 학습 루프를 돌며, train 데이터로 학습하고, validation 데이터로 성능을 측정한다. 각 배치마다 세션이 종료된 위치의 hidden state를 초기화하여 GRU의 상태를 정확하게 유지하도록 한다.\n",
    "- reset_hidden_states(model, mask) -> mask에 해당하는 세션의 GRU hidden state만 선별적으로 0으로 초기화한다.\n",
    "- get_metrics(data, model, args, k) -> validation/test 데이터로 예측하고, Recall@k, MRR@k를 계산한다. 이때, 마지막 배치 크기가 부족할 경우 0으로 패딩하여 모델에 입력하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35743a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 셋으로 학습하면서 valid 셋으로 검증합니다.\n",
    "def train_model(model, args):\n",
    "    train_dataset = SessionDataset(args.tr)\n",
    "    train_loader = SessionDataLoader(train_dataset, batch_size=args.batch_size)\n",
    "\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        total_step = len(args.tr) - args.tr['UserId'].nunique()\n",
    "        tr_loader = tqdm(train_loader, total=total_step // args.batch_size, desc='Train', mininterval=1)\n",
    "        for feat, target, mask in tr_loader:\n",
    "            reset_hidden_states(model, mask)  # 종료된 session은 hidden_state를 초기화합니다. 아래 메서드에서 확인해주세요.\n",
    "\n",
    "            input_ohe = to_categorical(feat, num_classes=args.num_items)\n",
    "            input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "            target_ohe = to_categorical(target, num_classes=args.num_items)\n",
    "\n",
    "            result = model.train_on_batch(input_ohe, target_ohe)\n",
    "            tr_loader.set_postfix(train_loss=result[0], accuracy = result[1])\n",
    "\n",
    "        val_recall, val_mrr = get_metrics(args.val, model, args, args.k)  # valid set에 대해 검증합니다.\n",
    "\n",
    "        print(f\"\\t - Recall@{args.k} epoch {epoch}: {val_recall:3f}\")\n",
    "        print(f\"\\t - MRR@{args.k}    epoch {epoch}: {val_mrr:3f}\\n\")\n",
    "\n",
    "\n",
    "def reset_hidden_states(model, mask):\n",
    "    gru_layer = model.get_layer(name='GRU')  # model에서 gru layer를 가져옵니다.\n",
    "    hidden_states = gru_layer.states[0].numpy()  # gru_layer의 parameter를 가져옵니다.\n",
    "    for elt in mask:  # mask된 인덱스 즉, 종료된 세션의 인덱스를 돌면서\n",
    "        hidden_states[elt, :] = 0  # parameter를 초기화 합니다.\n",
    "    gru_layer.reset_states(states=hidden_states)\n",
    "\n",
    "\n",
    "def get_metrics(data, model, args, k: int):  # valid셋과 test셋을 평가하는 코드입니다.\n",
    "                                                     # train과 거의 같지만 mrr, recall을 구하는 라인이 있습니다.\n",
    "    dataset = SessionDataset(data)\n",
    "    loader = SessionDataLoader(dataset, batch_size=args.batch_size)\n",
    "    recall_list, mrr_list = [], []\n",
    "\n",
    "    total_step = len(data) - data['UserId'].nunique()\n",
    "\n",
    "    for inputs, label, mask in tqdm(loader, total=total_step // args.batch_size, desc='Evaluation', mininterval=1):\n",
    "        reset_hidden_states(model, mask)\n",
    "        input_ohe = to_categorical(inputs, num_classes=args.num_items)\n",
    "        input_ohe = np.expand_dims(input_ohe, axis=1) \n",
    "        # \n",
    "        if input_ohe.shape[0] < args.batch_size:\n",
    "            pad_len = args.batch_size - input_ohe.shape[0]\n",
    "            padding = np.zeros((pad_len, 1, args.num_items))\n",
    "            input_ohe = np.concatenate([input_ohe, padding], axis=0)\n",
    "\n",
    "        pred = model.predict(input_ohe, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "        pred_arg = tf.argsort(pred, direction='DESCENDING')  # softmax 값이 큰 순서대로 sorting 합니다.\n",
    "\n",
    "        length = len(inputs)\n",
    "        recall_list.extend([recall_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "        mrr_list.extend([mrr_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "    \n",
    "    \n",
    "    print(recall_list)\n",
    "    print(mrr_list)\n",
    "    recall, mrr = np.mean(recall_list), np.mean(mrr_list)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ea96083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [02:02<00:06, 30.23it/s, accuracy=0.0156, train_loss=6.63] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 1: 0.025641\n",
      "\t - MRR@20    epoch 1: 0.008547\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 32.03it/s, accuracy=0.0195, train_loss=6.2]  \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05263157894736842, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 2: 0.076923\n",
      "\t - MRR@20    epoch 2: 0.026991\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:54<00:05, 32.23it/s, accuracy=0.0273, train_loss=6.01] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0.08333333333333333, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07142857142857142, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14285714285714285, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 3: 0.076923\n",
      "\t - MRR@20    epoch 3: 0.007631\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f60f23",
   "metadata": {},
   "source": [
    "- 여기까지가 위에서 정의한 GRU 모델을 설정한 파라미터에 따라 학습을 진행한것이다. \n",
    "- 위의 결과들은, 훈련 데이터로 train_on_batch() 학습을 진행하고, 매 epoch마다 검증 성능을 출력한것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19fb1d6",
   "metadata": {},
   "source": [
    "## Step 5. 모델 테스트\n",
    "- 아래 코드는 학습이 완료된 모델을 테스트 데이터로 평가하여, 최종 성능 지표인 Recall@20과 MRR@20을 출력하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbaf4f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  50%|█████     | 1/2 [00:00<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0.14285714285714285, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.125, 0, 0, 0.07692307692307693, 0, 0, 0]\n",
      "\t - Recall@20: 0.068182\n",
      "\t - MRR@20: 0.007836\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, args, test):\n",
    "    test_recall, test_mrr = get_metrics(test, model, args, 20)\n",
    "    print(f\"\\t - Recall@{args.k}: {test_recall:3f}\")\n",
    "    print(f\"\\t - MRR@{args.k}: {test_mrr:3f}\\n\")\n",
    "\n",
    "test_model(model, args, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ae848",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea8f28",
   "metadata": {},
   "source": [
    "# [실험 4가지]\n",
    "- 실험 1) GRU hidden size 증가시키기 (hsz: 50(기존) -> 100)\n",
    "    - GRU의 hidden state 크기를 늘리면, 더 많은 정보를 보존할 수 있음 -> 더욱더 정교한 사용자의 행동을 예측 가능하다.\n",
    "- 실험 2) Learning Rate 증가시키기 (lr: 0.001(기존) -> 0.005)\n",
    "    - 학습 속도를 빠르게 하여 더 빠른 수렴을 만들도록 함\n",
    "- 실험 3) Dropout 증가시키기 (drop_rate: 0.1(기존) -> 0.3)\n",
    "- 실험 4) 패딩 방식 개선시키기\n",
    "    - 세션이 끝날 때 마지막 항목 기준으로 padding을 하여 GRU state를 더 적절하게 유지하도록 개선함\n",
    "    - 전처리 시 순서/패딩 전략을 개선한 tr, val, test 사용함\n",
    "    - 나머지 파라미터는 위의 baseline과 동일함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c11927",
   "metadata": {},
   "source": [
    "## 실험 1) GRU hidden size 증가시키기 (hsz: 50(기존) -> 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00dcb648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== 실험 1: GRU hidden size 증가 ========\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(256, 1, 3416)]          0         \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    [(256, 100), (256, 100)]  1055400   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (256, 100)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (256, 3416)               345016    \n",
      "=================================================================\n",
      "Total params: 1,400,416\n",
      "Trainable params: 1,400,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 31.99it/s, accuracy=0.0117, train_loss=6.27] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1111111111111111, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 1: 0.051282\n",
      "\t - MRR@20    epoch 1: 0.015670\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:54<00:05, 32.15it/s, accuracy=0.0469, train_loss=5.96] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0.07692307692307693, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14285714285714285, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 2: 0.076923\n",
      "\t - MRR@20    epoch 2: 0.010764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 32.06it/s, accuracy=0.0508, train_loss=5.79] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1111111111111111, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 3: 0.051282\n",
      "\t - MRR@20    epoch 3: 0.007123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  50%|█████     | 1/2 [00:00<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.125, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.125, 0, 0, 0, 0, 0.06666666666666667, 0]\n",
      "[실험 1 결과] Recall@20: 0.0682, MRR@20: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"======== 실험 1: GRU hidden size 증가 ========\")\n",
    "\n",
    "args_exp1 = Args(\n",
    "    tr=tr,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    batch_size=256,\n",
    "    hsz=100,  # 변경됨\n",
    "    drop_rate=0.1,\n",
    "    lr=0.001,\n",
    "    epochs=3,\n",
    "    k=20\n",
    ")\n",
    "\n",
    "model_exp1 = create_model(args_exp1)\n",
    "train_model(model_exp1, args_exp1)\n",
    "recall_exp1, mrr_exp1 = get_metrics(test, model_exp1, args_exp1, args_exp1.k)\n",
    "\n",
    "print(f\"[실험 1 결과] Recall@20: {recall_exp1:.4f}, MRR@20: {mrr_exp1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fd5727",
   "metadata": {},
   "source": [
    "## 실험 2) Learning Rate 증가시키기 (lr: 0.001(기존) -> 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9330b21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== 실험 2: Learning Rate 증가 ========\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(256, 1, 3416)]          0         \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    [(256, 50), (256, 50)]    520200    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (256, 50)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (256, 3416)               174216    \n",
      "=================================================================\n",
      "Total params: 694,416\n",
      "Trainable params: 694,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 32.05it/s, accuracy=0.0625, train_loss=6.02] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 1: 0.051282\n",
      "\t - MRR@20    epoch 1: 0.006838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 31.88it/s, accuracy=0.0586, train_loss=5.85] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 2: 0.025641\n",
      "\t - MRR@20    epoch 2: 0.006410\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 31.93it/s, accuracy=0.0664, train_loss=5.79] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 3: 0.025641\n",
      "\t - MRR@20    epoch 3: 0.005128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  50%|█████     | 1/2 [00:00<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0.16666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14285714285714285, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25, 0, 0, 0.05555555555555555, 0, 0, 0]\n",
      "[실험 2 결과] Recall@20: 0.0909, MRR@20: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"======== 실험 2: Learning Rate 증가 ========\")\n",
    "\n",
    "args_exp2 = Args(\n",
    "    tr=tr,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    batch_size=256,\n",
    "    hsz=50,\n",
    "    drop_rate=0.1,\n",
    "    lr=0.005,  # 변경됨\n",
    "    epochs=3,\n",
    "    k=20\n",
    ")\n",
    "\n",
    "model_exp2 = create_model(args_exp2)\n",
    "train_model(model_exp2, args_exp2)\n",
    "recall_exp2, mrr_exp2 = get_metrics(test, model_exp2, args_exp2, args_exp2.k)\n",
    "\n",
    "print(f\"[실험 2 결과] Recall@20: {recall_exp2:.4f}, MRR@20: {mrr_exp2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72e1a7",
   "metadata": {},
   "source": [
    "## 실험 3) Dropout 증가시키기 (drop_rate: 0.1(기존) -> 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10460a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== 실험 3: Dropout 증가 ========\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(256, 1, 3416)]          0         \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    [(256, 50), (256, 50)]    520200    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (256, 50)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (256, 3416)               174216    \n",
      "=================================================================\n",
      "Total params: 694,416\n",
      "Trainable params: 694,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 31.99it/s, accuracy=0.00391, train_loss=6.79]\n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 1: 0.025641\n",
      "\t - MRR@20    epoch 1: 0.006410\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 32.08it/s, accuracy=0.0156, train_loss=6.28] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0.06666666666666667, 0, 0]\n",
      "\t - Recall@20 epoch 2: 0.076923\n",
      "\t - MRR@20    epoch 2: 0.027350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:54<00:05, 32.18it/s, accuracy=0.0312, train_loss=6.14] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06666666666666667, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 3: 0.076923\n",
      "\t - MRR@20    epoch 3: 0.040171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  50%|█████     | 1/2 [00:00<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16666666666666666, 0, 0, 0, 0, 0, 0]\n",
      "[실험 3 결과] Recall@20: 0.0227, MRR@20: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"======== 실험 3: Dropout 증가 ========\")\n",
    "\n",
    "args_exp3 = Args(\n",
    "    tr=tr,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    batch_size=256,\n",
    "    hsz=50,\n",
    "    drop_rate=0.3,  # 변경됨\n",
    "    lr=0.001,\n",
    "    epochs=3,\n",
    "    k=20\n",
    ")\n",
    "\n",
    "model_exp3 = create_model(args_exp3)\n",
    "train_model(model_exp3, args_exp3)\n",
    "recall_exp3, mrr_exp3 = get_metrics(test, model_exp3, args_exp3, args_exp3.k)\n",
    "\n",
    "print(f\"[실험 3 결과] Recall@20: {recall_exp3:.4f}, MRR@20: {mrr_exp3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f17835",
   "metadata": {},
   "source": [
    "## 실험 4) 패딩 방식 개선시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30e37b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== 실험 4: 패딩 및 순서 보정 적용 ========\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(256, 1, 3416)]          0         \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    [(256, 50), (256, 50)]    520200    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (256, 50)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (256, 3416)               174216    \n",
      "=================================================================\n",
      "Total params: 694,416\n",
      "Trainable params: 694,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:53<00:05, 32.54it/s, accuracy=0.0117, train_loss=6.58] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.125, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 1: 0.051282\n",
      "\t - MRR@20    epoch 1: 0.016026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:56<00:05, 31.70it/s, accuracy=0.0234, train_loss=6.18] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0.16666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07692307692307693, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 2: 0.076923\n",
      "\t - MRR@20    epoch 2: 0.014793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 3690/3875 [01:55<00:05, 31.90it/s, accuracy=0.0391, train_loss=5.99] \n",
      "Evaluation:  33%|███▎      | 1/3 [00:00<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.09090909090909091, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t - Recall@20 epoch 3: 0.051282\n",
      "\t - MRR@20    epoch 3: 0.006605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  50%|█████     | 1/2 [00:00<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.058823529411764705, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0.05263157894736842, 0, 0, 0]\n",
      "[실험 4 결과] Recall@20: 0.0682, MRR@20: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"======== 실험 4: 패딩 및 순서 보정 적용 ========\")\n",
    "\n",
    "args_exp4 = Args(\n",
    "    tr=tr,  # padding/순서 개선된 데이터셋\n",
    "    val=val,\n",
    "    test=test,\n",
    "    batch_size=256,\n",
    "    hsz=50,\n",
    "    drop_rate=0.1,\n",
    "    lr=0.001,\n",
    "    epochs=3,\n",
    "    k=20\n",
    ")\n",
    "\n",
    "model_exp4 = create_model(args_exp4)\n",
    "train_model(model_exp4, args_exp4)\n",
    "recall_exp4, mrr_exp4 = get_metrics(test, model_exp4, args_exp4, args_exp4.k)\n",
    "\n",
    "print(f\"[실험 4 결과] Recall@20: {recall_exp4:.4f}, MRR@20: {mrr_exp4:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480237e",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8640b",
   "metadata": {},
   "source": [
    "### [실험 결과 및 정리]\n",
    "- 기존 Baseline\n",
    "    - Recall@20 = 0.0682, MRR@20 = 0.0078\n",
    "    - MRR은 낮지만 추천 시스템 기준으로는 나름 합리적인 Baseline 이라고 판단할 수 있다..!\n",
    "- 실험1) GRU hidden size 증가\n",
    "    - 변화 없음 (Recall 동일, MRR 약간 감소함)\n",
    "    - 모델 복잡도 증가가 성능에 크게 영향을 주지 않았음 → 오히려 미세하게 과적합 또는 gradient 소실 가능성을 보였다.\n",
    "- 실험 2) Learning Rate 증가\n",
    "    - Recall 0.0909 / MRR 0.0140 → 크게 성능 향상을 보였다!\n",
    "    - 가장 효과적인 실험으로 판단할 수 있다.\n",
    "    - 이는 학습 속도가 적절하게 증가해 빠르게 수렴하고 일반화 성능이 향상됐다고 볼 수 있다.\n",
    "- 실험 3) Dropout 증가\n",
    "    - Recall 0.0227 / MRR 0.0038 → 성능이 급감하였다.\n",
    "    - 과도한 정규화(?) → 모델이 충분히 학습하지 못한것을 알 수 있다.\n",
    "    - Dropout도 적당히 조절할 필요가 있음을 알 수 있다.\n",
    "- 실험 4) 패딩 방식 개선시키기\n",
    "    - Recall 동일 / MRR 약간 감소 -> 단순한 순서의 조정이 GRU 기반 구조에서는 통하지 않았음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ba5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995feb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
